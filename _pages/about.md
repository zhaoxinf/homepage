---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

About me
======

* I am a PhD student at the Hong Kong University of Science and Technology, supervised by Prof. [Kai Chen](https://cse.hkust.edu.hk/~kaichen/) at HKUST. Additionally, I am a scholar at Carnegie Mellon University (CMU), working with Prof [Min Xu](https://xulabs.github.io/group/). I also serve as the director of the  [Psyche.AI AVATAR Lab](https://www.psyai.com/home).

* My dream is to use technology to change the world. Specifically, I hope to build robots and digital humans that are indistinguishable from real humans, with the goal of achieving artificial general intelligence. Prior to joining HKUST, I was a PhD student at Renmin University of China, co-supervised by Prof. [Jun He](http://info.ruc.edu.cn/jsky/rtjs/index.htm) from RUC and Prof. [Hongyan Liu](https://www.sem.tsinghua.edu.cn/info/1210/32067.htm) from Tsinghua University (THU). Additionally, I have worked as a researcher at ByteDance, Neal, and DeepGLInt, focusing on computer vision research.

* My research interests lie in the areas of computer vision and machine learning, specifically in place recognition, 6D pose estimation, human body reconstruction, and medical image segmentation. Please feel free to contact me by email if you are interested in my research.


<br>

News!
======
* Two papers D-IF and Emo-Talk are accepted by ICCV 2023, one of the best conference in computer vision.
*  Excited to annouce that one of our  papers has been accepted by signal processing, IF=4.729
*  Excited to annouce that one of my papers has been accepted by IJCAI 2023.
*  I am honored to have returned to Carnegie Mellon University as a visiting scholar.
*  One of my papers has been accepted for presentation at CVPR 2023, which is considered one of the most prestigious computer vision conferences in the world.
* I am thrilled to have had one of my papers accepted for presentation at ICRA 2023, which is a leading robotics conference.
*  My research has been recognized at ECCV Workshop 2022, PRCV 2022, and ECCV 2022, all of which are highly-regarded international conferences in the field of computer vision.
*  I am proud to have had a paper accepted for publication in the ACM Computing Surveys journal, which is widely considered one of the best ACM journals with an impact factor of 14.324.
*  The virtual actor An-Ruohan of Psyai, which I helped to develop, performs her show daily on bilibili.
*  My research has also been recognized at ICIP 2022, which is a top-tier computer vision conference with a long-standing reputation for excellence.
* I am excited to announce that one of my papers has been accepted for presentation at AAAI 2022, which is a leading artificial intelligence conference.

<br>

Education
======
* PhD student at **Hong Kong University of Science and Technology**. Computer Science. 2023.1 to now.
* Visiting scholar at **Carnegie Mellon University**. Computer Science. 2021.12 to now.
* PhD student at **Renmin University of China**. Computer Science. 2019.09-2023.1

<br>

Work experience
======
* 2021～now:  Chief Young Scientist, Psyche AI Inc
  * Human body reconstruction
  * Talking head
  * 3d foundation models

* 2021～now: Remote algorithm researcher, Xreal
  * 6D object pose estimation
  * Point cloud completion
  * 3d foundation models
 
* 2020～2021: Intern, Bytedance Inc
  * 6D object pose estimation
  * 3D object detection
  * 3D object tracking
 
* 2020～2020: Intern, DeepGLInt
   * 3D segmentation
   * 3D fault detection

<br>



Selected Publications
======
* **EmoTalk: Speech-driven emotional disentanglement for 3D face animation** [[paper]](https://arxiv.org/pdf/2303.11089.pdf)[[code]](https://github.com/ZiqiaoPeng/EmoTalk)   
Ziqiao Peng, Haoyu Wu, Zhenbo Song, Hao Xu, Xiangyu Zhu, Hongyan Liu, Jun He, **Zhaoxin Fan(corresponding author)**.  
International Conference on Computer Vision, ICCV 2023

* **D-IF: Uncertainty-aware Human Digitization via Implicit Distribution Field** [[paper]](https://arxiv.org/pdf/2303.11089.pdf)[[code]](https://github.com/ZiqiaoPeng/EmoTalk)   
Xueting Yang, Yihao Luo, Yuliang Xiu, Wei Wang, Hao Xu, **Zhaoxin Fan(corresponding author)**.  
International Conference on Computer Vision, ICCV 2023

* **Reconstruction-Aware Prior Distillation for Semi-supervised Point Cloud Completion** [[paper]](https://arxiv.org/pdf/2204.09186.pdf)  
**Zhaoxin Fan**, Yulin He, Zhicheng Wang, Kejian Wu, Hongyan Liu and Jun He  
International Joint Conference on Artificial Intelligence, IJCAI 2023

* **Robust Single Image Reflection Removal Against Adversarial Attacks** [[paper]](https://openaccess.thecvf.com/content/CVPR2023/papers/Song_Robust_Single_Image_Reflection_Removal_Against_Adversarial_Attacks_CVPR_2023_paper.pdf)    
Zhenbo Song, Zhenyuan Zhang, Kaihao Zhang, Wenhan Luo, **Zhaoxin Fan**, Wenqi Ren, Jianfeng Lu   
IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2023

* **Object Level Depth Reconstruction for Category Level 6D Object Pose Estimation From Monocular RGB Image** [[paper]](https://arxiv.org/pdf/2204.01586.pdf)[[code]](https://github.com/FANzhaoxin666/OLD_Net_release)       
**Zhaoxin Fan**, Zhenbo Song, Jian Xu, Zhicheng Wang, Kejian Wu, Hongyan Liu and Jun He  
European Conference on Computer Vision, ECCV 2022

* **SVT-Net: Super Light-Weight Sparse Voxel Transformer for Large Scale Place Recognition** [[paper]](https://arxiv.org/pdf/2105.00149.pdf)[[code]](https://github.com/ZhenboSong/SVTNet)    
**Zhaoxin Fan**, Zhenbo Song, Zhiwu Lu, Hongyan Liu, Jun He, and Xiaoyong Du  
36th AAAI Conference on Artificial Intelligence, AAAI 2022

* **Deep Learning on Monocular Object Pose Detection and Tracking: A Comprehensive Overview** [[paper]](https://arxiv.org/pdf/2105.14291.pdf)  
**Zhaoxin Fan**, Yazhi Zhu, Yulin He, Qi Sun, Hongyan Liu, and Jun He  
ACM Computing Surveys, CSUR, 2022.

* **SRNet: A 3D Scene Recognition Network using Static Graph and Dense Semantic Fusion** [[paper]](https://onlinelibrary.wiley.com/doi/abs/10.1111/cgf.14146)    
**Zhaoxin Fan**, Hongyan Liu, Jun He, Qi Sun, and Xiaoyong Du  
Computer Graphics Forum, CGF 2020  


* **A Graph‐based One‐Shot Learning Method for Point Cloud Recognition** [[paper]](https://onlinelibrary.wiley.com/doi/abs/10.1111/cgf.14147)    
**Zhaoxin Fan**, Hongyan Liu, Jun He, Qi Sun, and Xiaoyong Du  
Computer Graphics Forum, CGF 2020 


Group Outings
======
<img src="https://github.com/zhaoxinf/zhaoxinf.github.io/tree/master/psyche.jpeg" width="960" height="480" />
<br>




